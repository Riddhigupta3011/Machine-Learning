{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCANIA APS FAILURE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Air Pressure System (APS) is an essential part of a heavy duty vehicle, where compressed air is used to press the piston that applies pressure on brake pads to stop the vehicle. It is also used in gear systems of these vehicles. The advantages of having an APS other than a hydraulic setup is the easy availability and sustainability of air from\n",
    "nature.\n",
    "\n",
    "This dataset consists of data, sourced from heavy duty Scania trucks, available publicly from the UCI machine learning repository. It consists of failure cases of the trucks during operation. The challenge was to predict the failure of the Air Pressure System (APS) in Scania trucks to avoid failure during truck operation which may lead to high maintenance cost.\n",
    "\n",
    "\n",
    "The data can be found at:\n",
    "https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a **Binary Classification** problem where the positive class tells us that the failure was due to a specific component of the APS, whereas, the negative class tells us that the failure has nothing to do with that component. \n",
    "\n",
    "Therefore, given a new datapoint (sensor information), we must build a model that would tell us if the failure was due to APS or not. If the model misses an APS failure, it may prove to be detremental during operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Latency must be fairly low, to detect a failure in the APS and avoid increase in maintenance cost.\n",
    "\n",
    "\n",
    "2. Cost of misclassification is very high since an APS failure which is not detected can lead to failure of the truck during operation and increase in maintenance cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset consists of **60,000 datapoints** and **171 features**, of which one is the class label. The features are a combination of numerical data and histogram bins data. The feature names are kept anonymized for proprietary reasons. 59,000 data points belong to the negative class and the remaining 1,000 belong to the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using **Macro-F1 Score** as our performance metric for this project. Macro F1 score takes in to account the F1 scores of each class. It may be beneficial in showing us the performance of our model based on the number of correctly classified points for both classes. This is useful because the cost of misclassification is very high since an APS failure which is not detected can lead to failure of the truck during operation and increase in maintenance cost.\n",
    "\n",
    "**Macro F1-score = average(F1-SCORE of all classes)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis + Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAA4CAYAAADuMJi0AAAGR0lEQVR42rVZ21IbRxBtCbQrkIR2dQVjsLmDLBsET3nTQ8ouYRkQVf6e/E9+Im958qMfkgoXAaKSSj6C9Jnd2R2NeiRSRaZqitVOT5+Z6dNnWoKGlN94JFp8Ipofkb/7SOXjGyp8wF+z35K3f0uUp/GW4XfLQ8v2gefj3ZCCzojoNfue+43o1Q3l3xB/yA3JO7jnF2pCLnI+pNyx/qw7L+SQ7T2N9p2f8c60QcfcK6KGXsAd+ZvA4LlZYuSSAoOhMs5vwJkEGDlbPMaJoA+FcQ0IH38QLWkbAFLkOOhoMF5tU6/eBRhNjro0ZgKiPRAt3FLhCO/vqdgmNTm32LkmKpvBmQY4q5uAaAgbwDBG2BVv3bfI8KKAMWj2kfw9+pkZREIbEql4ST1x7hgHIANkbJ//MF8mAH/ilTCJ2tIi4ASr1IC3VNqXHKOxjy34mgoImnOQtx1g81fkqTiMOBVGcTogNhiT5iBHET8R8C+iApJUmgim3SQAXhsLQz7ee2G8gOAQNtJckBEplADiAxtX+G9NmhDl0qJKnTvyWlAMPYZnvIviGXRg6/Dh824DBXhP/tbfREXJEIvQ+aaPGjG7pvw6r3xdx+9hqb4dgZaP2XmdHO2K/B0c1+oUph6k8kShBryl/Ft0DYgjTlOieOACHFFpVyUl72T9V3cM1jUoYvxIC2vpCSys/ck70mDYuYvdvKjlMdKAUThneWVU1aAsyjv6PURDiwNsHGBZzY+JtAAgE2TFxdRHJdyIp/f+zqu09M5cDP2F08Ukkpj4YNSdX950HY2pNCCUK/Hhx5ZMBfjNSEzdsIihVzzAMdn9dz4eDYhnyQb9SSCiAryiJcQk82LiTbJ4x2FZJaUenpKnzP95WyDf4Y+QN9EFHHSeDLGdBjjKNQ5vKHf4XMA7KrY0y0GEObBOO/8e1ywuQExOHXktuQyJALEBpcEqhwtHqgiDuCK5b6i0p2MQpcckIIoh+6hYgTZtO8xlMi6O4tKCF/kOGHEg/W0UUpHW0ZoGNZ1ExZWcn7EErgwt4uj50E/sFBjXXIayWvh7WryjasxarZKssXon0zxvvkc32Q0bqbBCuZiKt9dWFysfQefeL29JYFaeztX6tePaZdz5mYx8+6Zq3Mk0wXECQxlhdzgS2wjBHju3j1RIgKyOMdNUE8X0+RAdbSapS11MRCv1SzUXmO6wGZe2SQYrv2MvCSWEv2VODE6DN7bz8ufypgQKW7uQskFTQHULLKyaEyrnlZbgOGLrV5qrn9U79jjm2HJmgkaVN98AfBub91lGPLZBqdroN5LYgjSu4zYZDDHXZOIPC691HqrWI1900I8qLzgKP4ft8DxEWigprPfrO+KcXno9gZz4jjGewWdUcpGCj0qVFuGPYbl2VturndZ2qRvlL8acDO6lF/DY/VjsFesiUK+ypJ+r/ep+cJkSQxEK4PG4WozgA75TYrDDqStE69K8/mzGEM+JXTeqvmedEElMmwCMm2SLd6bNNF9su02zEtoW6nAQtpMj5Gd7fKa//wqonF7UdtHFsVn+6hf1o7AfriPH7M6EeIUEF5zKVxXbYo7kS/OEtOqDYZKPoBsETIixn0uYrasThmzDkhdKPkz2EnaX0HdQbIgr59vAdGYDqjHrxkjS7WOxkTD8sqEqhiwcJETgBYigrBqF08KyDaje9SZ/I1A7MzaTzMGDEulPtZUkuKcyIRAjxEJPVrnVlb/9wkfij31D/pQt1IN+iL8bGJcstBIO7Y5VI/cwDqURbXhMuJxBqD0KLoK3esWFs0Jz5i5ZvJUAfFJMFb9XmGIOnzGpijpcWYCaMqXSQWp8EnCABepQ0Elyi4wfKfsw78ikIqif1pe1AGPlLmojl1SKxHHXp1L+Ut7AmDQHvhI5xHGi4EooO2BR7k78PEkJOdL7cAxQUZ/Tyclu9gnfwGgOmm2lNHGNmZXsq4Pqgc1EG1ATrvKl8s4R9ywwnqulGUnaRLVhxy8v3ieUwy2hbooT68uscW++DCDH0WSzuoyN2D4LUJ/tLECbcSKznwMIFs0ChF4mRTCnQbIIfk4SHJo6A9BMuTnXTs3Ku/KxsgZWqzuSe+Os8cEUfnMBY6UF5gi3SUbd5K7vDjq5WW0UENJlRsWn4sy21Er/E/AvPQSFHy1p4fgAAAAASUVORK5CYII=');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.stats import uniform,randint\n",
    "from tqdm import tqdm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from prettytable import PrettyTable\n",
    "import pickle\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 171)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>76698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520.0</td>\n",
       "      <td>493384.0</td>\n",
       "      <td>721044.0</td>\n",
       "      <td>469792.0</td>\n",
       "      <td>339156.0</td>\n",
       "      <td>157956.0</td>\n",
       "      <td>73224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>33058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400.0</td>\n",
       "      <td>178064.0</td>\n",
       "      <td>293306.0</td>\n",
       "      <td>245416.0</td>\n",
       "      <td>133654.0</td>\n",
       "      <td>81140.0</td>\n",
       "      <td>97576.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>41040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.280000e+02</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378.0</td>\n",
       "      <td>159812.0</td>\n",
       "      <td>423992.0</td>\n",
       "      <td>409564.0</td>\n",
       "      <td>320746.0</td>\n",
       "      <td>158022.0</td>\n",
       "      <td>95128.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>60874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.368000e+03</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012.0</td>\n",
       "      <td>229790.0</td>\n",
       "      <td>405298.0</td>\n",
       "      <td>347188.0</td>\n",
       "      <td>286954.0</td>\n",
       "      <td>311560.0</td>\n",
       "      <td>433954.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  aa_000  ab_000        ac_000  ad_000  ae_000  af_000  ag_000  ag_001  \\\n",
       "0   neg   76698     NaN  2.130706e+09   280.0     0.0     0.0     0.0     0.0   \n",
       "1   neg   33058     NaN  0.000000e+00     NaN     0.0     0.0     0.0     0.0   \n",
       "2   neg   41040     NaN  2.280000e+02   100.0     0.0     0.0     0.0     0.0   \n",
       "3   neg      12     0.0  7.000000e+01    66.0     0.0    10.0     0.0     0.0   \n",
       "4   neg   60874     NaN  1.368000e+03   458.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   ag_002  ...     ee_002    ee_003    ee_004    ee_005    ee_006    ee_007  \\\n",
       "0     0.0  ...  1240520.0  493384.0  721044.0  469792.0  339156.0  157956.0   \n",
       "1     0.0  ...   421400.0  178064.0  293306.0  245416.0  133654.0   81140.0   \n",
       "2     0.0  ...   277378.0  159812.0  423992.0  409564.0  320746.0  158022.0   \n",
       "3     0.0  ...      240.0      46.0      58.0      44.0      10.0       0.0   \n",
       "4     0.0  ...   622012.0  229790.0  405298.0  347188.0  286954.0  311560.0   \n",
       "\n",
       "     ee_008  ee_009  ef_000  eg_000  \n",
       "0   73224.0     0.0     0.0     0.0  \n",
       "1   97576.0  1500.0     0.0     0.0  \n",
       "2   95128.0   514.0     0.0     0.0  \n",
       "3       0.0     0.0     4.0    32.0  \n",
       "4  433954.0  1218.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv(\"aps_failure_training_set.csv\",skiprows=20,na_values=[\"na\"])\n",
    "print(x.shape)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Train datapoints:  60000\n",
      "Total number of features:  171\n",
      "The column/feature names given are:\n",
      "  ['class', 'aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000', 'ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009', 'ah_000', 'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000', 'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000', 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009', 'az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007', 'az_008', 'az_009', 'ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'bb_000', 'bc_000', 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000', 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000', 'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000', 'ck_000', 'cl_000', 'cm_000', 'cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009', 'co_000', 'cp_000', 'cq_000', 'cr_000', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006', 'cs_007', 'cs_008', 'cs_009', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000', 'dh_000', 'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000', 'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', 'dx_000', 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', 'ee_000', 'ee_001', 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009', 'ef_000', 'eg_000']\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of Train datapoints: \",x.shape[0])\n",
    "print(\"Total number of features: \",x.shape[1])\n",
    "\n",
    "print(\"The column/feature names given are:\\n \",list(x.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pre-Processing and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class label Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg' 'pos']\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "def get_correct_label(y):\n",
    "    \"\"\"\n",
    "    This function converts the class labels\n",
    "    from 'neg' and 'pos' to 0 and 1 respectively\n",
    "    \"\"\"\n",
    "    return y.replace(['neg','pos'],[0,1])\n",
    "\n",
    "print(x['class'].unique())\n",
    "x['class'] = get_correct_label(x['class'])\n",
    "print(x['class'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will look into the distribution of our dataset. In ideal cases, we prefer a balanced dataset (equal number of positive and negative datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive class points is:  1000\n",
      "The number of negative class points is:  59000\n"
     ]
    }
   ],
   "source": [
    "# Plotting the distribution of class label\n",
    "sns.barplot(x['class'].unique(),x['class'].value_counts())\n",
    "plt.title('Class Label Distribution')\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "print('The number of positive class points is: ',x['class'].value_counts()[1])\n",
    "print('The number of negative class points is: ',x['class'].value_counts()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "This dataset is **highly imbalanced** as the number of negative class points are much much more than the positive class points. We can choose to upsample the minority class datapoints, or use a modified classifier to tackle this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for single value features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the available features, the ones that have the same value for all datapoints do not hold much importance in improving performance of our model. Hence, we can discard those features.\n",
    "\n",
    "We can remove the features that have standard deviation = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features that are dropped due to having a constant value (0 std. dev.) are:  ['cd_000']\n",
      "Shape of our feature set:  (60000, 170)\n"
     ]
    }
   ],
   "source": [
    "def constant_value(df):\n",
    "    \"\"\"\n",
    "    This function returns a list of columns\n",
    "    that have std. deviation of 0\n",
    "    meaning, all values are constant\n",
    "    \"\"\"\n",
    "    constant_value_feature = []\n",
    "    info = df.describe()\n",
    "    for i in df.columns:\n",
    "        if info[i]['std']==0:\n",
    "            constant_value_feature.append(i)\n",
    "    df.drop(constant_value_feature,axis=1,inplace=True)\n",
    "    return df,constant_value_feature\n",
    "\n",
    "x , dropped_feature = constant_value(x)\n",
    "print(\"The features that are dropped due to having a constant value (0 std. dev.) are: \",dropped_feature)\n",
    "print(\"Shape of our feature set: \",x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is known to have a high number of missing values. Lets have a closer look into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary whose keys are the column names and values are the percentage of missing values\n",
    "nan_count = {k:list(x.isna().sum()*100/x.shape[0])[i] for i,k in enumerate(x.columns)}\n",
    "\n",
    "# Sorting the dictionary in descending order based on the percentage of missing values\n",
    "nan_count = {k: v for k, v in sorted(nan_count.items(), key=lambda item: item[1],reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting a graph showing the top 15 features having highest percentage of missing values \n",
    "sns.set_style(style=\"whitegrid\")\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# Bar Plot\n",
    "plot = sns.barplot(x= list(nan_count.keys())[:15],y = list(nan_count.values())[:15],palette=\"hls\")\n",
    "\n",
    "# Add annotations above each bar signifying their value\n",
    "for p in plot.patches:\n",
    "        plot.annotate('{:.1f}%'.format(p.get_height()), (p.get_x()+0.2, p.get_height()+1))\n",
    "\n",
    "# Make y-axis more interpretable\n",
    "plot.set_yticklabels(map('{:.1f}%'.format, plot.yaxis.get_majorticklocs())) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "* It is very evident that the some features have more than 50% missing values out of the total 60,000 datapoints. In the next section, we will see how to handle our missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do we handle the missing values?**\n",
    "* We will discard features with more than 70% missing values. \n",
    "* For features with missing values less than 5%, we can drop those rows. \n",
    "* For features with missing values between 5-15%, we will impute those missing values using mean/median. \n",
    "* Now for the rest of the features with missing value% between 15-70% missing values, use model based imputation technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping features and rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earlier shape of x: (60000, 170)\n",
      "Shape after removal of rows and columns: (55973, 163)\n",
      "Number of features having missing values below 5%: 128\n"
     ]
    }
   ],
   "source": [
    "def remove_na(df,nan_feat):\n",
    "    \"\"\"\n",
    "    This function removes features having more than 70%\n",
    "    missing data, and removes rows that have NA values\n",
    "    from features that have less than 5% missing data\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Removing features having more than 70% NA\n",
    "    df = df.dropna(axis = 1, thresh=18000)\n",
    "\n",
    "    # Removing rows having NA from above created list of features\n",
    "    df = df.dropna(subset=nan_feat)\n",
    "\n",
    "    # Reset Index values \n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "print(\"Earlier shape of x:\",x.shape)\n",
    "\n",
    "# List of features having less than 5% NA\n",
    "na_5 = [k for k,v in nan_count.items() if v < 5]\n",
    "\n",
    "x = remove_na(x,na_5)\n",
    "print(\"Shape after removal of rows and columns:\",x.shape)\n",
    "print(\"Number of features having missing values below 5%:\",len(na_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features Removed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed features are: ['br_000', 'bq_000', 'bp_000', 'bo_000', 'ab_000', 'cr_000', 'bn_000', 'cd_000']\n"
     ]
    }
   ],
   "source": [
    "# creating a list of the top 7 features having highest number of missing values\n",
    "na_70 = list(nan_count.keys())[:7]\n",
    "\n",
    "# Total removed features\n",
    "removed_features = na_70 + dropped_feature\n",
    "print(\"Removed features are:\", removed_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seperating Attributes and Class Label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating the class label from the other attributes after the NAN rows/columns were deleted\n",
    "y_train = x['class']\n",
    "x_train = x.drop('class',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputation of Missing Values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model based Imputation / Multivariate Imputation by Chained Equations (MICE)**:\n",
    "\n",
    "Ref:https://scikit-learn.org/stable/modules/impute.html#iterative-imputer\n",
    "\n",
    "For features having 15% to 70% missing values, we will perform an Iterative model based imputation technique called MICE. At each step, a feature with missing values is designated as output y and the other feature columns are treated as inputs X. A regressor ( we have used Ridge Regressor ) is fit on (X, y) for known y. Then, the regressor is used to predict the missing values of y. This is done for each feature in an iterative fashion, and then is repeated for max_iter (10 as default) imputation rounds. The results of the final imputation round are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features whose missing values are imputed with median are:\n",
      " 14\n"
     ]
    }
   ],
   "source": [
    "def imputation(df,mis_col):\n",
    "    \"\"\"\n",
    "    This function imputes Missing values \n",
    "    using Median on given features, and\n",
    "    Model Based Imputation on the rest\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Using sklearn's SimpleImputer\n",
    "    median_imputer = SimpleImputer(missing_values=np.NaN , strategy='median',copy=True)\n",
    "\n",
    "    # Creating a new dataframe of imputed values\n",
    "    median_df = median_imputer.fit_transform(df[mis_col])\n",
    "    df1 = df.copy()\n",
    "    df1[mis_col] = median_df\n",
    "\n",
    "    # Performing Model-Based Imputation\n",
    "    mice_imputer = IterativeImputer(estimator=Ridge(random_state=0),\n",
    "                                    random_state=0)\n",
    "    imputed_df = pd.DataFrame(data = mice_imputer.fit_transform(df1) , columns= df1.columns )\n",
    "\n",
    "    return imputed_df , median_imputer , mice_imputer\n",
    "\n",
    "\n",
    "# List of feature names that have missing values between 5% to 15%.\n",
    "# We will impute the missing values in features with their median\n",
    "median_imputed_features = [k for k,v in nan_count.items() if v >= 5 and v < 15]\n",
    "\n",
    "imputed_x_train , MEDIAN_imputer , MICE_imputer = imputation( x_train , median_imputed_features )\n",
    "print(\"Number of features whose missing values are imputed with median are:\\n\",len(median_imputed_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Preprocessing Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we read our test dataset, we will pass it through a function 'preprocess_test_data()' that will perform the complete data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 171)\n",
      "Total number of Train datapoints:  16000\n",
      "Total number of features:  171\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>66002</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>495076.0</td>\n",
       "      <td>380368.0</td>\n",
       "      <td>440134.0</td>\n",
       "      <td>269556.0</td>\n",
       "      <td>1315022.0</td>\n",
       "      <td>153680.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>59816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>540820.0</td>\n",
       "      <td>243270.0</td>\n",
       "      <td>483302.0</td>\n",
       "      <td>485332.0</td>\n",
       "      <td>431376.0</td>\n",
       "      <td>210074.0</td>\n",
       "      <td>281662.0</td>\n",
       "      <td>3232.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>1814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7646.0</td>\n",
       "      <td>4144.0</td>\n",
       "      <td>18466.0</td>\n",
       "      <td>49782.0</td>\n",
       "      <td>3176.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  aa_000  ab_000  ac_000  ad_000  ae_000  af_000  ag_000  ag_001  \\\n",
       "0   neg      60     0.0    20.0    12.0     0.0     0.0     0.0     0.0   \n",
       "1   neg      82     0.0    68.0    40.0     0.0     0.0     0.0     0.0   \n",
       "2   neg   66002     2.0   212.0   112.0     0.0     0.0     0.0     0.0   \n",
       "3   neg   59816     NaN  1010.0   936.0     0.0     0.0     0.0     0.0   \n",
       "4   neg    1814     NaN   156.0   140.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   ag_002  ...    ee_002    ee_003    ee_004    ee_005     ee_006    ee_007  \\\n",
       "0     0.0  ...    1098.0     138.0     412.0     654.0       78.0      88.0   \n",
       "1     0.0  ...    1068.0     276.0    1620.0     116.0       86.0     462.0   \n",
       "2     0.0  ...  495076.0  380368.0  440134.0  269556.0  1315022.0  153680.0   \n",
       "3     0.0  ...  540820.0  243270.0  483302.0  485332.0   431376.0  210074.0   \n",
       "4     0.0  ...    7646.0    4144.0   18466.0   49782.0     3176.0     482.0   \n",
       "\n",
       "     ee_008  ee_009  ef_000  eg_000  \n",
       "0       0.0     0.0     0.0     0.0  \n",
       "1       0.0     0.0     0.0     0.0  \n",
       "2     516.0     0.0     0.0     0.0  \n",
       "3  281662.0  3232.0     0.0     0.0  \n",
       "4      76.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = pd.read_csv(\"aps_failure_test_set.csv\",skiprows=20,na_values=[\"na\"])\n",
    "print(x_test.shape)\n",
    "print(\"Total number of Train datapoints: \",x_test.shape[0])\n",
    "print(\"Total number of features: \",x_test.shape[1])\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Test data: (16000, 162)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_test_data( x , na_features , median_features , imputer_median , imputer_mice):\n",
    "    # Replace 'neg' and 'pos' with 0,1 in our dataset\n",
    "    x['class'] = x['class'].replace(['neg','pos'],[0,1])\n",
    "    \n",
    "    # Seperate Class label from the rest of the dataset\n",
    "    y = x['class']\n",
    "    x = x.drop('class',axis=1)\n",
    "    \n",
    "    # Drop Features with high percentage of missing values\n",
    "    x = x.drop(na_features , axis=1)\n",
    "    \n",
    "    x[median_features] = imputer_median.transform(x[median_features])\n",
    "    \n",
    "    x = pd.DataFrame(data = imputer_mice.transform(x) , columns= x.columns )\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "\n",
    "x_test , y_test = preprocess_test_data(x_test,\n",
    "                                       removed_features,\n",
    "                                       median_imputed_features,\n",
    "                                       MEDIAN_imputer,\n",
    "                                       MICE_imputer )\n",
    "print(\"Shape of Test data:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving our preprocessed data and preprocessing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../imputed_train_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m df_to_save \u001b[38;5;241m=\u001b[39m imputed_x_train\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      4\u001b[0m df_to_save[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_train\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdf_to_save\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../imputed_train_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Save TEST SET\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Code to save our csv file to avoid re-doing above imputations every time\u001b[39;00m\n\u001b[0;32m      9\u001b[0m df_to_save \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3540\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3542\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3543\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3544\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3548\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3549\u001b[0m )\n\u001b[1;32m-> 3551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mline_terminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_terminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3554\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3556\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3568\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1162\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1163\u001b[0m     line_terminator\u001b[38;5;241m=\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1179\u001b[0m )\n\u001b[1;32m-> 1180\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../imputed_train_data.csv'"
     ]
    }
   ],
   "source": [
    "# Save TRAIN SET\n",
    "# Code to save our csv file to avoid re-doing above imputations every time\n",
    "df_to_save = imputed_x_train.copy()\n",
    "df_to_save['class'] = y_train\n",
    "df_to_save.to_csv(\"../imputed_train_data.csv\",index=False)\n",
    "\n",
    "# Save TEST SET\n",
    "# Code to save our csv file to avoid re-doing above imputations every time\n",
    "df_to_save = x_test.copy()\n",
    "df_to_save['class'] = y_test\n",
    "df_to_save.to_csv(\"../imputed_test_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_x_train = pd.read_csv(\"../imputed_train_data.csv\")\n",
    "y_train = imputed_x_train['class']\n",
    "imputed_x_train = imputed_x_train.drop('class',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating the two types of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was given to us that certain features are histogram bin information, and the prefix (letter before the ' _ ') is the Identifier and the suffix is the bin_id.(Identifier_Bin)\n",
    "\n",
    "To find the features that are contain histogram bin information, we know that all features from a single histogram have the same prefix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Identifier_Bin_count(x):\n",
    "    \"\"\"\n",
    "    This function finds the identifiers\n",
    "    and the number of bins in each identifier\n",
    "    \"\"\"\n",
    "    prefix = []\n",
    "    # For each feature name, find it's Identifier and count  \n",
    "    for name in x.columns:\n",
    "        prefix.append(name.split('_')[0])\n",
    "    counter = Counter(prefix)\n",
    "    return list(counter.keys()),list(counter.values())\n",
    "\n",
    "feature_prefix , bin_count = Identifier_Bin_count(imputed_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the same\n",
    "plt.figure(figsize=(24,5))\n",
    "sns.barplot(x = feature_prefix,y = bin_count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "We can see that there are 7 sets of features having 10 bins each. In other words, there are **7 histograms divided into 10 bins each**. \n",
    "\n",
    "eg: Identifier 'ag' consists of ag_000, ag_001, ag_002, ag_003, ag_004, ag_005, ag_006, ag_007, ag_008 and ag_009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Identifier of the histogram features\n",
    "hist_identifier = [feature_prefix[i] for i,j in enumerate(bin_count) if j==10]\n",
    "print(\"The Histogram Identifiers are: \",hist_identifier)\n",
    "\n",
    "# Getting the names of the features having histograms bin information\n",
    "hist_features = [i for i in x_train.columns if i.split('_')[0] in hist_identifier]\n",
    "print(\"\\nThere are\",len(hist_features),\"features that contain histogram bin information and they are: \\n\",hist_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seperating Histogram Features from the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_data = imputed_x_train[hist_features]\n",
    "x_without_hist = imputed_x_train.drop(hist_features,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will select the top features from both the datasets using the complete imputed set. But the Analysis will be performed on the data having missing values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Top Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform data analysis on the top 15 features from our histogram dataset.\n",
    "For selecting the features, we will perform **Recursive Feature Elimination**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top(df,y,n):\n",
    "    \"\"\"\n",
    "    This function returns the top n features,\n",
    "    by performing Recursive Feature Elimination\n",
    "    using Random Forest Classifier\n",
    "    \"\"\"\n",
    "    # Use RFE algorithm from sklearn to perform feature selection\n",
    "    feature_select = RFE(estimator=RandomForestClassifier(n_estimators=150,max_depth=5,random_state=1),\n",
    "                         n_features_to_select=n,\n",
    "                         verbose=5)\n",
    "    feature_select.fit(df,y)\n",
    "\n",
    "    # support_ gives an array of True/False for each feature where True signifies that the feature is selected\n",
    "    top_f = [ c for i,c in enumerate(df.columns.tolist()) if feature_select.support_[i] ]   \n",
    "    return top_f\n",
    "\n",
    "top_feature_hist = get_top(histogram_data,y_train,15)\n",
    "print(\"The top features selected after Recursive Feature Elimination are: \\n\",top_feature_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe which is a subset of our original dataset and consists of only the top features and the class label\n",
    "\n",
    "# WE WILL BE USING THE DATA WHICH CONSISTS OF MISSING VALUES FOR OUR EDA\n",
    "top_features = pd.DataFrame(data=x_train[top_feature_hist],columns=top_feature_hist)\n",
    "top_features['class'] = y_train\n",
    "top_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Histogram Features Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis of Histogram Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(x):\n",
    "    \"\"\"\n",
    "    This function prints Mean and Std. Deviation of points of each class,\n",
    "    plots the Probability Density Function,Cumulative Density Function \n",
    "    and the Box-Plot of each feature of the given data\n",
    "    \"\"\"\n",
    "    for n in x.columns.tolist():\n",
    "        if n != 'class':\n",
    "\n",
    "            describe_0 = x[x['class']==0].describe()\n",
    "            describe_1 = x[x['class']==1].describe()\n",
    "\n",
    "            fig,ax = plt.subplots(1,3,figsize=(12,4))\n",
    "            \n",
    "            print( '\\033[1m' + \"Feature '{}' , Class Label 1, Mean: {}\".format(n , round(describe_1[n].iloc[1],2) ) )\n",
    "            print( \"Standard Deviation {} \".format( round(describe_1[n].iloc[2],2) ) )\n",
    "            print( \"\\nFeature '{}' , Class Label 0, Mean: {}\".format(n , round(describe_0[n].iloc[1],2) ) )\n",
    "            print( \"And Standard Deviation is {} \".format( round(describe_0[n].iloc[2],2) ) )\n",
    "            \n",
    "            sns.set_theme(style='white')\n",
    "            # Plot PDF of points belonging to negative class\n",
    "            sns.distplot(x[x['class']==0][n],ax=ax[0],hist=False)\n",
    "            # Plot PDF of points belonging to positive class \n",
    "            sns.distplot(x[x['class']==1][n],ax=ax[0],hist=False)\n",
    "            # Plot CDF of the feature values\n",
    "            sns.kdeplot(data=x, x=x[n], hue=\"class\",cumulative=True, common_norm=False, common_grid=True,ax=ax[1])\n",
    "            # Plot the Box-Plot\n",
    "            sns.boxplot(x=x['class'],y=x[n],ax=ax[2])\n",
    "            plt.show()\n",
    "            print('*'*100)\n",
    "\n",
    "plots(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "*   Plots of features **ag_003, ay_008, ba_002, ba_003, ba_004, cn_004, cs_002, cs_004, ee_003 and ee_005** show us that the Lower values of the features indicate no failure in the APS component. A higher value clearly indicates an APS component failure\n",
    "\n",
    "\n",
    "*   Around 99% values of feature **ag_001 and ay_005**, where there is no failure in the APS component, are 0.\n",
    "\n",
    "\n",
    "*   We can say that in these top features, a higher value may indicate a failure in the truck's Air Pressure System\n",
    "\n",
    "\n",
    "*   But, there are few cases when the values are higher than usual, but still do not lead to APS failure. Example: Feature **ee_005**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Correlation Between the Top Features + Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will check how each top feature is correlated w.r.t to other top features using the Pearson Correaltion Value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Correlation Heatmap      \n",
    "plt.figure(figsize=(20,11))\n",
    "sns.heatmap(top_features.corr(),annot=True)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which feature is the most uncorrelated w.r.t the target variable?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting correlation coeffiecients of features w.r.t class\n",
    "correlation_values = top_features.corr().loc['class']\n",
    "\n",
    "# Get top 5 features\n",
    "top_correlated_features = correlation_values.sort_values().iloc[:5].index.tolist()\n",
    "print(\"Most Uncorrelated Feature is\",top_correlated_features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "\n",
    "*   Taking into consideration only how each feature is correlated with the target variable ('class'), we can observe that feature **'ay_005'** is the most uncorrelated feature among our top attributes. \n",
    "\n",
    "*  We can perform further Bivariate Analysis on how the other top 5 features vary w.r.t feature 'ay_005'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(df,feature,percentile_value):\n",
    "    \"\"\"\n",
    "    This function plots scatter plots between \n",
    "    all the features of the dataframe, w.r.t a given feature\n",
    "    \"\"\"\n",
    "    fig,ax = plt.subplots(1,5,figsize=(19,4))\n",
    "\n",
    "    # Only include the data consisting of values below the given percentile\n",
    "    p = np.nanpercentile(df[feature],percentile_value)\n",
    "    df = df[df[feature]<p]\n",
    "    \n",
    "    columns = df.columns.tolist()\n",
    "    for i in range(len(columns)):\n",
    "        if columns[i] !='class':\n",
    "            # Plot scatterplot between 2 given features\n",
    "            sns.scatterplot(x=df[columns[i]],y=df[feature],hue=df['class'],ax=ax[i])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print('\\033[1m'+\"Variation of top features w.r.t feature\",top_correlated_features[0])\n",
    "plot_scatter(top_features[top_correlated_features + ['class']],top_correlated_features[0],95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "*   **ag_002, ag_001, cn_000**:  It can be seen from the scatter plot that for any value of the other top features, there is failure in the APS component (class label = 1) when the value in feature 'ay_005' is nearly 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function created earlier to select top features\n",
    "top_feature_num = get_top(x_without_hist , y_train , 15)\n",
    "print(\"The top features selected after Recursive Feature Elimination are: \\n\",top_feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe which is a subset of our original dataset and consists of only the top features and the class label\n",
    "\n",
    "# WE WILL BE USING THE DATA WHICH CONSISTS OF MISSING VALUES FOR OUR EDA\n",
    "top_features = pd.DataFrame(data=x_train[top_feature_num],columns=top_feature_num)\n",
    "top_features['class'] = y_train\n",
    "top_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the plot function created earlier\n",
    "plots(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "* **aa_000 :** If there is no failure in the APS (class label = 0), about 95% of the points have a value below *0.1x1e6*. A higher value than that usually indicates a failure in the APS component.\n",
    "\n",
    "\n",
    "* **al_000, am_000 :** The values of instances of failure and non-failure of the APS component are not clearly seperable in this feature. Although points of the failure cases do have a slightly higher value.\n",
    "\n",
    "\n",
    "* **ap_000, aq_000, bj_000, bu_000 :** Instances of failure have a higher value, compared to non-failure cases. But there are few instances of non-failure of the APS component, that see higher values in this feature.\n",
    "\n",
    "\n",
    "* In all features, except **dg_000, cj_000, am_0 and al_000**, the higher values in the features usually indicate failure in APS component. But due to the Imbalanced nature of the data this may not be certain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Correlation Between the Top Features + Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will check how each top feature is correlated w.r.t to other top features using the Pearson Correaltion Value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Correlation Heatmap      \n",
    "plt.figure(figsize=(20,11))\n",
    "sns.heatmap(top_features.corr(),annot=True)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which feature is the most uncorrelated w.r.t the target variable?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting correlation coeffiecients of features w.r.t class\n",
    "correlation_values = top_features.corr().loc['class']\n",
    "\n",
    "# Get top 5 features\n",
    "top_correlated_features = correlation_values.sort_values().iloc[:5].index.tolist()\n",
    "print(\"Most Uncorrelated Feature is\",top_correlated_features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "\n",
    "*   Taking into consideration only how each feature is correlated with the target variable ('class'), we can observe that feature **'dx_000'** is the most uncorrelated feature among our top attributes. \n",
    "\n",
    "*  We can perform further **Bivariate Analysis** on how the other top features are, w.r.t feature 'dx_000'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m'+\"Variation of top features w.r.t feature\",top_correlated_features[0])\n",
    "# Calling the plot function created earlier\n",
    "plot_scatter(top_features[top_correlated_features + ['class']],top_correlated_features[0],90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "* The main observation in all plots here is that for any value of the remaining features, if the feature 'dx_000' has a low value ( nearly 0 ), it MAY INDICATE that there is a failure in the APS component (class label=1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing our EDA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The dataset consists of 60,000 datapoints and 171 features including the class label.\n",
    "\n",
    "\n",
    "2. After plotting the count of each class label, we found that out of 60000 points, 59000 points belong to class 0 and the remaining 1000 points belong to class 1. We are working with a highly **Imbalanced Binary Classification** problem.\n",
    "\n",
    "\n",
    "3. We then went forward to check for missing values in our dataset. We observed that some features have more than 70% of their values missing. We decided to remove those features from our dataset. 7 features were thuse removed.\n",
    "\n",
    "\n",
    "4. There was one feature ( cd_000 ) that had a single value for all datapoints. And we decided to remove the same, since it will not add much value to our model performance.\n",
    "\n",
    "\n",
    "5. For features with less than **5%** missing data, the rows consisting of NA values were removed. Features with **5% - 15%** missing values were imputed using **median**. And features with **15% - 70%** missing values were imputed using a **model based imputation technique**.   \n",
    "\n",
    "\n",
    "6. There are 70 features which consist of bin information from 7 histograms. Each histogram has 10 bins. The Histogram features are the ones which have Identifiers: **['ag', 'ay', 'az', 'ba', 'cn', 'cs', 'ee']**. The histogram and numerical features were seperated into two datasets and we performed **Univariate and Bivariate Analysis** on the top 15 features of both the datasets. \n",
    "\n",
    "\n",
    "7. From performing Recursive Feature Elimination with a Random Forest Classifier, we found our top 15 features from the histogram dataset to be : **['ag_001', 'ag_002', 'ag_003', 'ay_005', 'ay_006', 'ay_008', 'ba_002', 'ba_003', 'ba_004', 'cn_000', 'cn_004', 'cs_002', 'cs_004', 'ee_003', 'ee_005']**.\n",
    "\n",
    "\n",
    "8. Analysis of the features show that in these top features, a higher value may indicate a failure in the truck's Air Pressure System. But, there are few cases when the values are higher than usual, but still do not lead to APS failure. Example: Feature **ee_005**. Univariate Analysis on the most uncorrelated feature w.r.t the target variable (**ay_005**) we saw that for **ag_002, ag_001, cn_000** - for any value of these other top features, there is failure in the APS component (class label = 1) when the value in feature 'ay_005' is nearly 0.\n",
    "\n",
    "\n",
    "9. From performing Recursive Feature Elimination with a Random Forest Classifier, we found our top 15 features from the numerical dataset to be : **['aa_000', 'al_000', 'am_0', 'ap_000', 'aq_000', 'bj_000', 'bu_000', 'bv_000', 'ci_000', 'cj_000', 'cq_000', 'dg_000', 'dn_000', 'do_000', 'dx_000']**.\n",
    "\n",
    "\n",
    "10. From Univariate Analysis, we saw that in all features, except **dg_000, cj_000, am_0 and al_000**, the higher values in the features usually indicate failure in APS component. But due to the Imbalanced nature of the data this may not be certain. Feature **'dx_000'** was the most uncorrelated feature among the top features. We performed **Bivariate Analysis** similar to the histogram top features, and the main observation in all plots here is that for any value of the remaining features, if the feature 'dx_000' has a low value ( nearly 0 ), it **MAY INDICATE** that there is a failure in the APS component (class label=1).."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our dataset consisting of imputed data\n",
    "X_train = pd.read_csv(\"../imputed_train_data.csv\")\n",
    "Y_train = X_train['class']\n",
    "X_train = X_train.drop('class',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A target variable with a large spread of values, in turn, may result in large error gradient values during optimization, making the learning process unstable. To avoid this, we will scale our data using sklearn's **MinMaxScaler**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(df):\n",
    "    \"\"\"\n",
    "    This function transforms features \n",
    "    by scaling each feature to a given range\n",
    "    \"\"\"\n",
    "    min_max = MinMaxScaler()\n",
    "    df = pd.DataFrame( data = min_max.fit_transform(df) , columns = df.columns )\n",
    "    return df , min_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Minority Oversampling Technique (SMOTE) for Imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem with imbalanced classification is that there are too few examples of the minority class for a model to effectively learn the decision boundary. One way to solve this problem is to oversample the examples in the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(df,label):\n",
    "    \"\"\"\n",
    "    This function balances the dataset by \n",
    "    creating dulicates of minority class points\n",
    "    \"\"\"\n",
    "    over = SMOTE(sampling_strategy=0.3)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    df, label = pipeline.fit_resample(df, label)\n",
    "    return df, label\n",
    "\n",
    "X_train , Y_train = balance_data(X_train , Y_train)\n",
    "print(X_train.shape)\n",
    "print(Y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to save our csv file to avoid re-doing above processing every time\n",
    "# For TRAIN DATA\n",
    "df_to_save = X_train.copy()\n",
    "df_to_save['class'] = Y_train\n",
    "df_to_save.to_csv(\"../final_train_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our dataset consisting of imputed data\n",
    "X_train = pd.read_csv(\"../final_train_data.csv\")\n",
    "Y_train = X_train['class']\n",
    "X_train = X_train.drop('class',axis=1)\n",
    "\n",
    "# Loading Test data\n",
    "X_test = pd.read_csv(\"../imputed_test_data.csv\")\n",
    "Y_test = X_test['class']\n",
    "X_test = X_test.drop('class',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Scaled data for Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_scale,scaler = scale_data(X_train)\n",
    "X_test_scale = pd.DataFrame(data = scaler.transform(X_test) , columns=X_test.columns)\n",
    "print(X_train_scale.shape,X_test_scale.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning( x , y , model , params , cv=10 ,verbose=10 ):\n",
    "    \"\"\"\n",
    "    This function performs HyperParameter Tuning\n",
    "    using GridSearchCV for the given model and it's parameters\n",
    "    \"\"\"\n",
    "    # Define the model that performs Hyperparameter tuning\n",
    "    clf = GridSearchCV(estimator= model,\n",
    "                       param_grid= params,\n",
    "                       scoring= 'f1_macro',\n",
    "                       cv= cv,                         \n",
    "                       verbose= verbose,\n",
    "                       n_jobs= -1)\n",
    "    \n",
    "    # Fit the model to the dataset\n",
    "    clf.fit( x , y )\n",
    "    return clf.best_params_ , clf.best_score_    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion( y_test , y_hat ):\n",
    "    \"\"\"\n",
    "    This function plots the Confusion Matrix\n",
    "    based on the true and predicted class labels\n",
    "    \"\"\"    \n",
    "    # Show Confusion Matrix Heatmap\n",
    "    cf_matrix_test = confusion_matrix(y_test , y_hat)\n",
    "        \n",
    "    group_names = [\"TN\",\"FP\",\"FN\",\"TP\"]\n",
    "    group_counts = [\"{}\".format(value) for value in cf_matrix_test.flatten()]\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_names,group_counts)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "    sns.heatmap(cf_matrix_test, annot=labels, fmt='', cmap='Blues')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results_pred( model , x_train , x_test , y_train , y_test ):\n",
    "    \"\"\"\n",
    "    This function predicts class label of the data,\n",
    "    and returns the Macro-F1 Score\n",
    "    \"\"\"\n",
    "    # Predic class labels\n",
    "    y_train_hat = model.predict(x_train)\n",
    "    y_test_hat = model.predict(x_test) \n",
    "    \n",
    "    f1_macro = f1_score(y_test, y_test_hat,average='macro')\n",
    "    \n",
    "    print('\\033[1m'+'Macro-F1 Score: ',f1_macro)\n",
    "    \n",
    "    # Plot Test Confusion Matrix\n",
    "    print(\"\\tTest Confusion Matrix\")\n",
    "    plot_confusion(y_test,y_test_hat)\n",
    "    \n",
    "    return f1_macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model using DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will predict all class labels to be 0 (majority class) and calculate the F1 score for the same. We can use sklearn's DummyClassifier to obtain our baseline results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyClassifier(strategy='constant',constant=0)\n",
    "dummy_model.fit(X_train,Y_train)\n",
    "\n",
    "F1_Base = model_results_pred( dummy_model , X_train , X_test , Y_train , Y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the different parameters for tuning\n",
    "params = {'C': np.random.uniform(0.001,1,5), 'tol':np.random.uniform(0.0001,0.1,5) }\n",
    "\n",
    "# Obtain best hyperparameters\n",
    "best_params_log , best_score_log = tuning(X_train_scale,\n",
    "                                          Y_train,\n",
    "                                          LogisticRegression(n_jobs=-1,random_state=42),\n",
    "                                          params,\n",
    "                                          cv=10,\n",
    "                                          verbose=2)\n",
    "\n",
    "\n",
    "print(\" Best Parameters:\",best_params_log,\"with score of:\",best_score_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = LogisticRegression(C= best_params_log['C'],\n",
    "                              tol= best_params_log['tol'],\n",
    "                              n_jobs=-1, \n",
    "                              random_state=42)\n",
    "\n",
    "LR_model.fit(X_train_scale,Y_train)\n",
    "\n",
    "F1_LR = model_results_pred( LR_model , X_train_scale , X_test_scale , Y_train , Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier with HingeLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the different parameters for tuning\n",
    "params = {'penalty': ['l1','l2'], 'alpha':np.random.uniform(0.0001,0.1,9) }\n",
    "\n",
    "# Obtain best hyperparameters\n",
    "best_params_sgd , best_score_sgd = tuning(X_train_scale,\n",
    "                                          Y_train,\n",
    "                                          SGDClassifier(n_jobs=-1,random_state=0),\n",
    "                                          params,\n",
    "                                          cv=10,\n",
    "                                          verbose=1)\n",
    "\n",
    "\n",
    "print(\" Best Parameters:\",best_params_sgd,\"with score of:\",best_score_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_model = SGDClassifier(penalty= best_params_sgd['penalty'],\n",
    "                          alpha= best_params_sgd['alpha'],\n",
    "                          n_jobs= -1,\n",
    "                          random_state= 0)\n",
    "\n",
    "SVM_model.fit(X_train_scale,Y_train)\n",
    "\n",
    "F1_SVM = model_results_pred( SVM_model , X_train_scale , X_test_scale , Y_train , Y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the different parameters for tuning\n",
    "params = {'var_smoothing': np.random.uniform(1e-16,1e-14,100)}\n",
    "\n",
    "# Obtain best hyperparameters\n",
    "best_params_nb , best_score_nb = tuning(X_train,\n",
    "                                        Y_train,\n",
    "                                        GaussianNB(),\n",
    "                                        params,\n",
    "                                        cv=10,\n",
    "                                        verbose=2)\n",
    "\n",
    "\n",
    "print(\" Best Parameters:\",best_params_nb,\"with score of:\",best_score_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our model\n",
    "NB_model = GaussianNB(var_smoothing=best_params_nb['var_smoothing'])\n",
    "\n",
    "\n",
    "# Fit and predict, and obtain train and test scores\n",
    "NB_model.fit(X_train,Y_train)\n",
    "\n",
    "F1_NB = model_results_pred(NB_model , X_train , X_test , Y_train , Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the different parameters for tuning\n",
    "params = {'max_depth': np.random.randint(10,25,5)}\n",
    "\n",
    "# Obtain best hyperparameters\n",
    "best_params_dt , best_score_dt = tuning(X_train,\n",
    "                                        Y_train,\n",
    "                                        DecisionTreeClassifier(),\n",
    "                                        params,\n",
    "                                        cv=11)\n",
    "\n",
    "\n",
    "print(\" Best Parameters:\",best_params_dt,\"with score of:\",best_score_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our model\n",
    "DT_model = DecisionTreeClassifier(max_depth = best_params_dt['max_depth'])\n",
    "\n",
    "# Fit and predict, and obtain train and test scores\n",
    "DT_model.fit(X_train,Y_train)\n",
    "\n",
    "F1_DT = model_results_pred( DT_model , X_train , X_test , Y_train , Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': [300,500,600,650,700],\n",
    "          'max_depth': [80,110,125,135]}\n",
    "\n",
    "\n",
    "# Obtain best hyperparameters\n",
    "best_params_rf , best_score_rf = tuning(X_train,\n",
    "                                        Y_train,\n",
    "                                        RandomForestClassifier(n_jobs= -1 , verbose= 1),\n",
    "                                        params,\n",
    "                                        cv=7)\n",
    "\n",
    "\n",
    "print(\" Best Parameters:\",best_params_rf,\"with score of:\",best_score_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our model\n",
    "RF_model = RandomForestClassifier(n_estimators = best_params_rf['n_estimators'],\n",
    "                                  max_depth = best_params_rf['max_depth'],\n",
    "                                  n_jobs = -1,\n",
    "                                  verbose = 0)\n",
    "\n",
    "\n",
    "# Fit and predict, and obtain train and test scores\n",
    "RF_model.fit(X_train,Y_train)\n",
    "# Fit and predict, and obtain train and test scores\n",
    "F1_RF = model_results_pred(RF_model , X_train , X_test , Y_train , Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':[100, 250,350,500],\n",
    "          'max_depth': [4,6,10,15],\n",
    "          'learning_rate':[0.001,0.01,0.1,1,10]}\n",
    "\n",
    "\n",
    "# Obtain best hyperparameters\n",
    "best_params_gb , best_score_gb = tuning(X_train,\n",
    "                                        Y_train,\n",
    "                                        LGBMClassifier(n_jobs=-1,random_state=42),\n",
    "                                        params,\n",
    "                                        cv=6)\n",
    "\n",
    "\n",
    "print(\" Best Parameters:\",best_params_gb,\"with score of:\",best_score_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our model\n",
    "GB_model = LGBMClassifier(n_estimators = best_params_gb['n_estimators'],\n",
    "                          max_depth = best_params_gb['max_depth'],\n",
    "                          learning_rate = best_params_gb['learning_rate'],\n",
    "                          n_jobs = -1,\n",
    "                          random_state = 42) \n",
    "\n",
    "\n",
    "# Fit and predict, and obtain train and test scores\n",
    "GB_model.fit(X_train , Y_train)\n",
    "# Fit and predict, and obtain train and test scores\n",
    "F1_GB = model_results_pred(GB_model , X_train , X_test , Y_train , Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':[ 400 , 600 , 650 , 700 , 750 , 800 ]}\n",
    "\n",
    "\n",
    "# Obtain best hyperparameters\n",
    "best_params_ab , best_score_ab = tuning(X_train,\n",
    "                                        Y_train,\n",
    "                                        AdaBoostClassifier(random_state=42),\n",
    "                                        params,\n",
    "                                        cv=4)\n",
    "\n",
    "\n",
    "print(\" Best Parameters:\",best_params_ab,\"with score of:\",best_score_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our model\n",
    "AB_model = AdaBoostClassifier(random_state=42,\n",
    "                              n_estimators = best_params_ab['n_estimators']) \n",
    "\n",
    "\n",
    "# Fit and predict, and obtain train and test scores\n",
    "AB_model.fit(X_train , Y_train)\n",
    "# Fit and predict, and obtain train and test scores\n",
    "F1_AB = model_results_pred(AB_model , X_train , X_test , Y_train , Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Ensemble (Stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the Train Dataset 50-50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data( x , y ):\n",
    "    D_1 , D_2 , Y_1 , Y_2 = train_test_split( x , y , stratify=y , test_size = 0.5 )\n",
    "    \n",
    "    D_1 = D_1.reset_index(drop=True)\n",
    "    D_2 = D_2.reset_index(drop=True)\n",
    "    \n",
    "    Y_1 = Y_1.reset_index(drop=True)\n",
    "    Y_2 = Y_2.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    return D_1 , D_2 , Y_1 , Y_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sampling with replacement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_samples( input_data , target_data ):\n",
    "    \"\"\"\n",
    "    This function samples 60% of \n",
    "    the given data, with replacements\n",
    "    \"\"\"\n",
    "    selecting_rows = np.random.choice(list(range(input_data.shape[0])),\n",
    "                                      size=int(0.6 * len(input_data)),\n",
    "                                      replace=True)\n",
    "    \n",
    "    sample_data = input_data.iloc[ selecting_rows  ]\n",
    "    target_of_sample_data = target_data.iloc[selecting_rows]\n",
    "\n",
    "    return sample_data , target_of_sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create k sample sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_list( x , y , n):\n",
    "    \"\"\"\n",
    "    This function creates a list of all\n",
    "    n samples and their corresponding outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    list_input_data =[]\n",
    "    list_output_data =[]\n",
    "\n",
    "    for i in range(0,n):\n",
    "        a,b = generating_samples(x,y)\n",
    "        list_input_data.append(a)\n",
    "        list_output_data.append(b)\n",
    "    return list_input_data, list_output_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtain trained base models (Decision Tree Classifier) for each sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_models(x,y,n):\n",
    "    \"\"\"\n",
    "    This function trains a base model for\n",
    "    each of the given sample dataset\n",
    "    and stores them in a dictionary\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "    # For each sample dataset\n",
    "    for i in tqdm(range(n)):\n",
    "        # Base Model: Decision Tree Classifier\n",
    "        best_model = DecisionTreeClassifier() \n",
    "        # Fit the model on the sample data\n",
    "        best_model.fit( x[i] , y[i] )\n",
    "        # Store the trained model\n",
    "        models['model_'+str(i)] = best_model\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pass dataset through each base model and create meta dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata( n , pred):\n",
    "    \"\"\"\n",
    "    This function creates a pandas Dataframe\n",
    "    consisting of the predictions of all the \n",
    "    base models as its features\n",
    "    \"\"\"\n",
    "    df=pd.DataFrame()\n",
    "    # For each base model\n",
    "    for i in range(n):\n",
    "        # Create feature prediction_i which consists of predictions of model i\n",
    "        df['prediction_'+str(i)] = pred[i]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_k_models( base, x , y ):\n",
    "    \"\"\"\n",
    "    In this function, a dataset passes through the \n",
    "    trained base models, and creates a new dataset\n",
    "    using these predictions as features\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    # For each base model\n",
    "    for model in base.values():\n",
    "        # Predict class label of test data\n",
    "        y_hat = model.predict(x)   \n",
    "        # Append the predictions to a list\n",
    "        predictions.append(y_hat)\n",
    "    \n",
    "    # Call function create_metadata to create new dataset\n",
    "    df = create_metadata( len(base) , predictions)\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_evaluation( base , meta , x , y ):\n",
    "    \"\"\"\n",
    "    This function passes a dataset through each base model,\n",
    "    merges the results into a dataframe, passes it through\n",
    "    a meta model, and gives the final Macro-F1 Score\n",
    "    \"\"\"\n",
    "    predictions=[]\n",
    "    # For each base model\n",
    "    for model in base.values():\n",
    "        # Predict class label and add append results into a list\n",
    "        y_hat = model.predict(x)\n",
    "        predictions.append(y_hat)\n",
    "        \n",
    "    # Create a new dataset consisting of the predictions\n",
    "    test_metadata = create_metadata( len(base) , predictions)\n",
    "    \n",
    "    # pass the new dataset through a meta model\n",
    "    final_y_hat = meta.predict(test_metadata)\n",
    "\n",
    "    return final_y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def custom_ensemble( x_train , y_train , x_test , n_estimators ):\n",
    "    \"\"\"\n",
    "    This function runs our custom Ensemble Model\n",
    "    on the given dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    D_1 , D_2 , Y_1 , Y_2 = split_data( x_train , y_train )\n",
    "    # Pass the dataset through each of the given functions\n",
    "        \n",
    "    # Generate n samples and add it into a list\n",
    "    list_input_data, list_output_data = sample_list( D_1 , Y_1 , n_estimators )\n",
    "        \n",
    "    # Train n base models \n",
    "    base_models = train_base_models( list_input_data , list_output_data ,n_estimators )\n",
    "    \n",
    "    # Predict on other half of the data (D2) and create new metadataset\n",
    "    model_predictions  = predict_k_models( base_models , D_2 , Y_2)\n",
    "        \n",
    "    # Fit the meta model to the above created dataset\n",
    "    meta_model  = XGBClassifier(learning_rate=0.1,\n",
    "                                max_depth= 10,\n",
    "                                n_estimators=500,\n",
    "                                eval_metric='logloss'\n",
    "                                ).fit(model_predictions , Y_2)\n",
    "        \n",
    "    # Evaluate and return Macro-F1 score of the custom model\n",
    "    y_hat = ensemble_evaluation( base_models , meta_model , X_test , Y_test )\n",
    "    \n",
    "        \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HyperParameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Parameters\n",
    "params = [ 100 , 150 , 200 , 300 ]\n",
    "\n",
    "scores={}\n",
    "# for each \"number of base models\"\n",
    "for n in params:\n",
    "    # Predict class label of test data for each parameter\n",
    "    y_hat = custom_ensemble( X_train, Y_train , X_test , n )\n",
    "    # Compute Macro-F1 score\n",
    "    # Add to dictionary as (n:f1_score)\n",
    "    scores[str(n)] = f1_score( Y_test , y_hat , average='macro' )\n",
    "    \n",
    "best_k = max(scores, key=scores.get) \n",
    "print(best_k) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify n_estimators\n",
    "n_estimators = int(best_k)\n",
    "# Predict Class labels using our custom ensemble\n",
    "y_hat = custom_ensemble( X_train, Y_train , X_test , n_estimators )\n",
    "\n",
    "# Compute Macro-F1 score\n",
    "F1_custom = f1_score( Y_test , y_hat , average='macro')\n",
    "print(\"Macro-F1 score is \",F1_custom)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plot_confusion(Y_test , y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=PrettyTable()\n",
    "\n",
    "table.field_names = ['Model','Macro-F1 Score']\n",
    "table.add_row(['Baseline',F1_Base])\n",
    "table.add_row(['Logistic Regression',F1_LR])\n",
    "table.add_row(['SGD using HingeLoss',F1_SVM])\n",
    "table.add_row(['Naive Bayes',F1_NB])\n",
    "table.add_row(['Decision Trees',F1_DT])\n",
    "table.add_row(['Random Forest',F1_RF])\n",
    "table.add_row(['Gradient Boosted Decision Trees',F1_GB])\n",
    "table.add_row(['Adaptive Boosting',F1_AB])\n",
    "table.add_row(['Custom Stacking Ensemble',F1_custom])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
