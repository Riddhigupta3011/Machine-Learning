{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "o4mZtmIr88Mm",
    "outputId": "59e38e9b-e899-4b07-ce2f-06b4fed7fafb"
   },
   "outputs": [],
   "source": [
    "#Importing the colab drive library to get the dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KwjX77yI9JGN"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"spam.csv\", encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "xeROP7Wg9dRM",
    "outputId": "fd07b91d-ab2b-4754-a801-20518f4539af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0-O6lxH-vUd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_26368\\1279663868.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  dataset = dataset.drop('Unnamed: 2', 1)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_26368\\1279663868.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  dataset = dataset.drop('Unnamed: 3', 1)\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_26368\\1279663868.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  dataset = dataset.drop('Unnamed: 4', 1)\n"
     ]
    }
   ],
   "source": [
    "#removing unnamed columns\n",
    "dataset = dataset.drop('Unnamed: 2', 1)\n",
    "dataset = dataset.drop('Unnamed: 3', 1)\n",
    "dataset = dataset.drop('Unnamed: 4', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "A1brZure-z3y",
    "outputId": "51960929-170e-46d0-f473-3344790206d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rndTDtNUFlDS"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns = {'v1':'label','v2':'message'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "2DtvXve5ygbp",
    "outputId": "30790c44-e351-4015-a142-89ad19b1e448"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4825   4516                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "f6TyUk6aFnaI",
    "outputId": "f75d8aba-9ee9-4afb-bc05-bbd8fc7de93e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "uD5MljD31w4Q",
    "outputId": "0eddf926-e365-45aa-e2fd-a9bb3ca81070"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_Class=pd.value_counts(dataset[\"label\"], sort= True)\n",
    "count_Class.plot(kind = 'bar',color = [\"green\",\"red\"])\n",
    "plt.title('Bar Plot')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "RGhCRxTeF5WN",
    "outputId": "9c0cc2a6-a140-4a95-cbd0-62985f873f46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8404)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = feature_extraction.text.CountVectorizer(stop_words = 'english')\n",
    "X = f.fit_transform(dataset[\"message\"])\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YB_wSIqeIEfv"
   },
   "source": [
    "**Implementing Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2d-TvYtgH8XA"
   },
   "outputs": [],
   "source": [
    "# Classifying spam and not spam msgs as 1 and 0\n",
    "\n",
    "dataset[\"label\"]=dataset[\"label\"].map({'spam':1,'ham':0})\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, dataset['label'], test_size=0.70, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIQD09AZIid8"
   },
   "outputs": [],
   "source": [
    "list_alpha = np.arange(1/100000, 20, 0.11)\n",
    "score_train = np.zeros(len(list_alpha))\n",
    "score_test = np.zeros(len(list_alpha))\n",
    "recall_test = np.zeros(len(list_alpha))\n",
    "precision_test= np.zeros(len(list_alpha))\n",
    "count = 0\n",
    "for alpha in list_alpha:\n",
    "    bayes = naive_bayes.MultinomialNB(alpha=alpha)\n",
    "    bayes.fit(X_train, y_train)\n",
    "    score_train[count] = bayes.score(X_train, y_train)\n",
    "    score_test[count]= bayes.score(X_test, y_test)\n",
    "    recall_test[count] = metrics.recall_score(y_test, bayes.predict(X_test))\n",
    "    precision_test[count] = metrics.precision_score(y_test, bayes.predict(X_test))\n",
    "    count = count + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "s9BMRkPlI9zb",
    "outputId": "fb872903-1a69-445b-e92a-69ae60cc2ccc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.998803</td>\n",
       "      <td>0.961805</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.820998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.11001</td>\n",
       "      <td>0.998803</td>\n",
       "      <td>0.966163</td>\n",
       "      <td>0.946360</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.22001</td>\n",
       "      <td>0.999402</td>\n",
       "      <td>0.967444</td>\n",
       "      <td>0.938697</td>\n",
       "      <td>0.837607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.33001</td>\n",
       "      <td>0.999402</td>\n",
       "      <td>0.968726</td>\n",
       "      <td>0.938697</td>\n",
       "      <td>0.844828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.44001</td>\n",
       "      <td>0.999402</td>\n",
       "      <td>0.971546</td>\n",
       "      <td>0.929119</td>\n",
       "      <td>0.867621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.55001</td>\n",
       "      <td>0.998803</td>\n",
       "      <td>0.976160</td>\n",
       "      <td>0.925287</td>\n",
       "      <td>0.899441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.66001</td>\n",
       "      <td>0.998803</td>\n",
       "      <td>0.976160</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.903955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.77001</td>\n",
       "      <td>0.997606</td>\n",
       "      <td>0.977698</td>\n",
       "      <td>0.917625</td>\n",
       "      <td>0.915870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.88001</td>\n",
       "      <td>0.997606</td>\n",
       "      <td>0.977954</td>\n",
       "      <td>0.909962</td>\n",
       "      <td>0.924125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.99001</td>\n",
       "      <td>0.997606</td>\n",
       "      <td>0.978980</td>\n",
       "      <td>0.902299</td>\n",
       "      <td>0.938247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alpha  Train Accuracy  Test Accuracy  Test Recall  Test Precision\n",
       "0  0.00001        0.998803       0.961805     0.913793        0.820998\n",
       "1  0.11001        0.998803       0.966163     0.946360        0.826087\n",
       "2  0.22001        0.999402       0.967444     0.938697        0.837607\n",
       "3  0.33001        0.999402       0.968726     0.938697        0.844828\n",
       "4  0.44001        0.999402       0.971546     0.929119        0.867621\n",
       "5  0.55001        0.998803       0.976160     0.925287        0.899441\n",
       "6  0.66001        0.998803       0.976160     0.919540        0.903955\n",
       "7  0.77001        0.997606       0.977698     0.917625        0.915870\n",
       "8  0.88001        0.997606       0.977954     0.909962        0.924125\n",
       "9  0.99001        0.997606       0.978980     0.902299        0.938247"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.matrix(np.c_[list_alpha, score_train, score_test, recall_test, precision_test])\n",
    "models = pd.DataFrame(data = matrix, columns = \n",
    "             ['alpha', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\n",
    "models.head(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "XEmJr7bJJBQL",
    "outputId": "b8d8b737-d586-43b8-d285-e5af679feae1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha             10.670010\n",
       "Train Accuracy     0.977259\n",
       "Test Accuracy      0.962574\n",
       "Test Recall        0.720307\n",
       "Test Precision     1.000000\n",
       "Name: 97, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index = models['Test Precision'].idxmax()\n",
    "models.iloc[best_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jtjtzP9wJJyj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xu4BP5EJtN5"
   },
   "source": [
    "**Random Forest Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "no3hqQoCJvyn"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100,max_depth=None,n_jobs=-1)\n",
    "rf_model = rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2JrMpC5CJxtK",
    "outputId": "1c63a779-9823-41e3-f017-4ac64f249995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.99 / Recall : 0.743 / fscore : 0.849 / Accuracy: 0.965\n"
     ]
    }
   ],
   "source": [
    "y_pred=rf_model.predict(X_test)\n",
    "precision,recall,fscore,support =score(y_test,y_pred,pos_label=1, average ='binary')\n",
    "print('Precision : {} / Recall : {} / fscore : {} / Accuracy: {}'.format(round(precision,3),round(recall,3),round(fscore,3),round((y_pred==y_test).sum()/len(y_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMcOkT3gKEN1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp39-cp39-win_amd64.whl (266.3 MB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.1.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.29.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (61.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.42.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.1.1)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.6.0)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.33.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 flatbuffers-22.12.6 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.11.0 libclang-14.0.6 oauthlib-3.2.2 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.29.0 termcolor-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47T_IDTWy8h0"
   },
   "source": [
    "**Using NLP techniques and using Tensorflow** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9PVGkzXy-ZG"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBWeH7Y-zHbn"
   },
   "outputs": [],
   "source": [
    "vocab_size = 400\n",
    "oov_tok = \"<OOV>\"\n",
    "max_length = 250\n",
    "embedding_dim = 16\n",
    "encode = ({'ham': 0, 'spam': 1} )\n",
    "#new dataset with replaced values\n",
    "dataset = dataset.replace(encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDV4kEu0zIlg"
   },
   "outputs": [],
   "source": [
    "X = dataset['message']\n",
    "Y = dataset['label']\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X)\n",
    "# convert to sequence of integers\n",
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GOI7t-VWzNI6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_26368\\42421382.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.array(X)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjewpYFdzRkc"
   },
   "outputs": [],
   "source": [
    "X = pad_sequences(X, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "Se11So0dzVOQ",
    "outputId": "58035107-b402-4d68-e256-58c1b065f348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 250, 16)           6400      \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                408       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,833\n",
      "Trainable params: 6,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fLPzLmwWzdqc",
    "outputId": "5ffeb929-b01c-43a3-8ba4-b0c87f970394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "140/140 - 1s - loss: 0.5293 - accuracy: 0.8649 - val_loss: 0.3836 - val_accuracy: 0.8700 - 1s/epoch - 8ms/step\n",
      "Epoch 2/50\n",
      "140/140 - 0s - loss: 0.3823 - accuracy: 0.8649 - val_loss: 0.3673 - val_accuracy: 0.8700 - 246ms/epoch - 2ms/step\n",
      "Epoch 3/50\n",
      "140/140 - 0s - loss: 0.3706 - accuracy: 0.8649 - val_loss: 0.3553 - val_accuracy: 0.8700 - 293ms/epoch - 2ms/step\n",
      "Epoch 4/50\n",
      "140/140 - 0s - loss: 0.3561 - accuracy: 0.8649 - val_loss: 0.3385 - val_accuracy: 0.8700 - 272ms/epoch - 2ms/step\n",
      "Epoch 5/50\n",
      "140/140 - 0s - loss: 0.3344 - accuracy: 0.8649 - val_loss: 0.3118 - val_accuracy: 0.8700 - 230ms/epoch - 2ms/step\n",
      "Epoch 6/50\n",
      "140/140 - 0s - loss: 0.2996 - accuracy: 0.8649 - val_loss: 0.2688 - val_accuracy: 0.8700 - 256ms/epoch - 2ms/step\n",
      "Epoch 7/50\n",
      "140/140 - 0s - loss: 0.2426 - accuracy: 0.8768 - val_loss: 0.2024 - val_accuracy: 0.9040 - 295ms/epoch - 2ms/step\n",
      "Epoch 8/50\n",
      "140/140 - 0s - loss: 0.1824 - accuracy: 0.9331 - val_loss: 0.1526 - val_accuracy: 0.9498 - 245ms/epoch - 2ms/step\n",
      "Epoch 9/50\n",
      "140/140 - 0s - loss: 0.1444 - accuracy: 0.9551 - val_loss: 0.1251 - val_accuracy: 0.9641 - 222ms/epoch - 2ms/step\n",
      "Epoch 10/50\n",
      "140/140 - 0s - loss: 0.1216 - accuracy: 0.9619 - val_loss: 0.1060 - val_accuracy: 0.9659 - 258ms/epoch - 2ms/step\n",
      "Epoch 11/50\n",
      "140/140 - 0s - loss: 0.1060 - accuracy: 0.9661 - val_loss: 0.0928 - val_accuracy: 0.9659 - 301ms/epoch - 2ms/step\n",
      "Epoch 12/50\n",
      "140/140 - 0s - loss: 0.0963 - accuracy: 0.9677 - val_loss: 0.0839 - val_accuracy: 0.9713 - 251ms/epoch - 2ms/step\n",
      "Epoch 13/50\n",
      "140/140 - 0s - loss: 0.0888 - accuracy: 0.9715 - val_loss: 0.0838 - val_accuracy: 0.9740 - 234ms/epoch - 2ms/step\n",
      "Epoch 14/50\n",
      "140/140 - 0s - loss: 0.0817 - accuracy: 0.9722 - val_loss: 0.0694 - val_accuracy: 0.9758 - 321ms/epoch - 2ms/step\n",
      "Epoch 15/50\n",
      "140/140 - 0s - loss: 0.0762 - accuracy: 0.9746 - val_loss: 0.0645 - val_accuracy: 0.9767 - 309ms/epoch - 2ms/step\n",
      "Epoch 16/50\n",
      "140/140 - 0s - loss: 0.0705 - accuracy: 0.9762 - val_loss: 0.0606 - val_accuracy: 0.9785 - 216ms/epoch - 2ms/step\n",
      "Epoch 17/50\n",
      "140/140 - 0s - loss: 0.0674 - accuracy: 0.9769 - val_loss: 0.0578 - val_accuracy: 0.9803 - 236ms/epoch - 2ms/step\n",
      "Epoch 18/50\n",
      "140/140 - 0s - loss: 0.0654 - accuracy: 0.9776 - val_loss: 0.0553 - val_accuracy: 0.9812 - 286ms/epoch - 2ms/step\n",
      "Epoch 19/50\n",
      "140/140 - 0s - loss: 0.0622 - accuracy: 0.9791 - val_loss: 0.0535 - val_accuracy: 0.9812 - 316ms/epoch - 2ms/step\n",
      "Epoch 20/50\n",
      "140/140 - 0s - loss: 0.0581 - accuracy: 0.9794 - val_loss: 0.0523 - val_accuracy: 0.9821 - 233ms/epoch - 2ms/step\n",
      "Epoch 21/50\n",
      "140/140 - 0s - loss: 0.0581 - accuracy: 0.9809 - val_loss: 0.0504 - val_accuracy: 0.9830 - 285ms/epoch - 2ms/step\n",
      "Epoch 22/50\n",
      "140/140 - 0s - loss: 0.0551 - accuracy: 0.9803 - val_loss: 0.0489 - val_accuracy: 0.9830 - 307ms/epoch - 2ms/step\n",
      "Epoch 23/50\n",
      "140/140 - 0s - loss: 0.0532 - accuracy: 0.9816 - val_loss: 0.0500 - val_accuracy: 0.9857 - 246ms/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "140/140 - 0s - loss: 0.0512 - accuracy: 0.9829 - val_loss: 0.0497 - val_accuracy: 0.9857 - 351ms/epoch - 3ms/step\n",
      "Epoch 25/50\n",
      "140/140 - 0s - loss: 0.0502 - accuracy: 0.9829 - val_loss: 0.0482 - val_accuracy: 0.9848 - 336ms/epoch - 2ms/step\n",
      "Epoch 26/50\n",
      "140/140 - 0s - loss: 0.0486 - accuracy: 0.9838 - val_loss: 0.0455 - val_accuracy: 0.9874 - 284ms/epoch - 2ms/step\n",
      "Epoch 27/50\n",
      "140/140 - 0s - loss: 0.0485 - accuracy: 0.9832 - val_loss: 0.0453 - val_accuracy: 0.9883 - 354ms/epoch - 3ms/step\n",
      "Epoch 28/50\n",
      "140/140 - 0s - loss: 0.0462 - accuracy: 0.9841 - val_loss: 0.0443 - val_accuracy: 0.9874 - 450ms/epoch - 3ms/step\n",
      "Epoch 29/50\n",
      "140/140 - 0s - loss: 0.0450 - accuracy: 0.9845 - val_loss: 0.0462 - val_accuracy: 0.9874 - 377ms/epoch - 3ms/step\n",
      "Epoch 30/50\n",
      "140/140 - 0s - loss: 0.0443 - accuracy: 0.9852 - val_loss: 0.0433 - val_accuracy: 0.9874 - 280ms/epoch - 2ms/step\n",
      "Epoch 31/50\n",
      "140/140 - 0s - loss: 0.0435 - accuracy: 0.9845 - val_loss: 0.0448 - val_accuracy: 0.9865 - 276ms/epoch - 2ms/step\n",
      "Epoch 32/50\n",
      "140/140 - 0s - loss: 0.0429 - accuracy: 0.9856 - val_loss: 0.0427 - val_accuracy: 0.9883 - 265ms/epoch - 2ms/step\n",
      "Epoch 33/50\n",
      "140/140 - 0s - loss: 0.0408 - accuracy: 0.9859 - val_loss: 0.0464 - val_accuracy: 0.9874 - 222ms/epoch - 2ms/step\n",
      "Epoch 34/50\n",
      "140/140 - 0s - loss: 0.0410 - accuracy: 0.9861 - val_loss: 0.0425 - val_accuracy: 0.9874 - 286ms/epoch - 2ms/step\n",
      "Epoch 35/50\n",
      "140/140 - 0s - loss: 0.0399 - accuracy: 0.9865 - val_loss: 0.0426 - val_accuracy: 0.9874 - 284ms/epoch - 2ms/step\n",
      "Epoch 36/50\n",
      "140/140 - 0s - loss: 0.0399 - accuracy: 0.9865 - val_loss: 0.0418 - val_accuracy: 0.9883 - 232ms/epoch - 2ms/step\n",
      "Epoch 37/50\n",
      "140/140 - 0s - loss: 0.0385 - accuracy: 0.9868 - val_loss: 0.0420 - val_accuracy: 0.9892 - 223ms/epoch - 2ms/step\n",
      "Epoch 38/50\n",
      "140/140 - 0s - loss: 0.0367 - accuracy: 0.9879 - val_loss: 0.0454 - val_accuracy: 0.9883 - 296ms/epoch - 2ms/step\n",
      "Epoch 39/50\n",
      "140/140 - 0s - loss: 0.0381 - accuracy: 0.9877 - val_loss: 0.0413 - val_accuracy: 0.9901 - 276ms/epoch - 2ms/step\n",
      "Epoch 40/50\n",
      "140/140 - 0s - loss: 0.0365 - accuracy: 0.9874 - val_loss: 0.0418 - val_accuracy: 0.9892 - 251ms/epoch - 2ms/step\n",
      "Epoch 41/50\n",
      "140/140 - 0s - loss: 0.0357 - accuracy: 0.9872 - val_loss: 0.0412 - val_accuracy: 0.9901 - 232ms/epoch - 2ms/step\n",
      "Epoch 42/50\n",
      "140/140 - 0s - loss: 0.0356 - accuracy: 0.9874 - val_loss: 0.0414 - val_accuracy: 0.9901 - 335ms/epoch - 2ms/step\n",
      "Epoch 43/50\n",
      "140/140 - 0s - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.0410 - val_accuracy: 0.9883 - 269ms/epoch - 2ms/step\n",
      "Epoch 44/50\n",
      "140/140 - 0s - loss: 0.0343 - accuracy: 0.9883 - val_loss: 0.0408 - val_accuracy: 0.9892 - 214ms/epoch - 2ms/step\n",
      "Epoch 45/50\n",
      "140/140 - 0s - loss: 0.0331 - accuracy: 0.9897 - val_loss: 0.0410 - val_accuracy: 0.9901 - 234ms/epoch - 2ms/step\n",
      "Epoch 46/50\n",
      "140/140 - 0s - loss: 0.0323 - accuracy: 0.9901 - val_loss: 0.0428 - val_accuracy: 0.9865 - 326ms/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "140/140 - 0s - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.0412 - val_accuracy: 0.9910 - 367ms/epoch - 3ms/step\n",
      "Epoch 48/50\n",
      "140/140 - 0s - loss: 0.0329 - accuracy: 0.9892 - val_loss: 0.0417 - val_accuracy: 0.9901 - 221ms/epoch - 2ms/step\n",
      "Epoch 49/50\n",
      "140/140 - 0s - loss: 0.0311 - accuracy: 0.9899 - val_loss: 0.0413 - val_accuracy: 0.9910 - 332ms/epoch - 2ms/step\n",
      "Epoch 50/50\n",
      "140/140 - 0s - loss: 0.0318 - accuracy: 0.9904 - val_loss: 0.0424 - val_accuracy: 0.9901 - 389ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.20, random_state=7)\n",
    "history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test,y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "f2W932zozgjY",
    "outputId": "22accfa7-5faf-4560-fe08-bd2b91efdee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9901\n",
      "[+] Accuracy: 99.01%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "loss = results[0]\n",
    "accuracy = results[1]\n",
    "\n",
    "\n",
    "print(f\"[+] Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCJQweUj1VSB"
   },
   "source": [
    "**Doing the Predictions from the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WAaIXT-1O4a"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3YyH_d91ZHD"
   },
   "outputs": [],
   "source": [
    "#Defining the function\n",
    "def get_predictions(txts):\n",
    "    txts = tokenizer.texts_to_sequences(txts)\n",
    "    txts = pad_sequences(txts, maxlen=max_length)\n",
    "    preds = model.predict(txts)\n",
    "    if(preds[0] > 0.5):\n",
    "        print(\"SPAM MESSAGE\")\n",
    "        \n",
    "    else:\n",
    "        print('NOT SPAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tsc76wCx1cT9",
    "outputId": "9f3606ab-7493-4007-c22f-6b2cc95a48f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step\n",
      "SPAM MESSAGE\n"
     ]
    }
   ],
   "source": [
    "txts=[\"You have won a free ticket to las vegas. Contact now\"]\n",
    "\n",
    "get_predictions(txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-6uQC6-K1jc2",
    "outputId": "6ab0769e-757b-49b7-a74e-c19a365a5c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "NOT SPAM\n"
     ]
    }
   ],
   "source": [
    "txts=[\"Hey there call me asap!!\"]\n",
    "\n",
    "get_predictions(txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eJuZctVd1lxb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SMS Spam Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
